{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-09T20:00:01.982232Z",
     "start_time": "2025-05-09T20:00:00.614104Z"
    }
   },
   "source": "from datasets import load_dataset",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\casvi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T20:00:11.015Z",
     "start_time": "2025-05-09T20:00:02.173777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_name = \"squad_v2\"\n",
    "dataset = load_dataset(dataset_name, split=\"train\")\n",
    "eval_dataset = load_dataset(dataset_name, split=\"validation\")\n",
    "print(\"dataset: \",dataset)\n",
    "print(\"eval_dataset: \",eval_dataset)"
   ],
   "id": "500b473b559b567d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 130319\n",
      "})\n",
      "eval_dataset:  Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 11873\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T20:00:13.267027Z",
     "start_time": "2025-05-09T20:00:11.039411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "if cuda_available:\n",
    "    device_id = 0  # You can change to 1,2,3 if you want other GPUs\n",
    "    torch.cuda.set_device(device_id)\n",
    "    # device = torch.device(f\"cuda:{device_id}\")\n",
    "    device = torch.device(f\"cuda:{device_id}\")\n",
    "    print(f\"🖥️ Using GPU {device_id}: {torch.cuda.get_device_name(device_id)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"⚙️ No GPU available, using CPU.\")\n",
    "\n",
    "print(f\"Device selected: {device}\")"
   ],
   "id": "1febccd54d7494b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🖥️ Using GPU 0: NVIDIA GeForce RTX 4070 SUPER\n",
      "Device selected: cuda:0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T20:00:30.325528Z",
     "start_time": "2025-05-09T20:00:13.277718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from unsloth import FastLanguageModel\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen3-4B-unsloth-bnb-4bit\",\n",
    "    max_seq_length = 4096,   # Context length - can be longer, but uses more memory\n",
    "    load_in_4bit = True,     # 4bit uses much less memory\n",
    "    load_in_8bit = False,    # A bit more accurate, uses 2x memory\n",
    "    full_finetuning = False, # We have full finetuning now!\n",
    "    # token = \"hf_...\",      # use one if using gated models\n",
    ")"
   ],
   "id": "46eb93bfa905de57",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.4.7: Fast Qwen3 patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4070 SUPER. Num GPUs = 2. Max memory: 11.994 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T20:00:34.630134Z",
     "start_time": "2025-05-09T20:00:30.372432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 64,           # Choose any number > 0! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 64,  # Best to choose alpha = rank or rank*2\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = True,   # We support rank stabilized LoRA\n",
    "    loftq_config = None,  # And LoftQ\n",
    ")"
   ],
   "id": "27782ee8b927aa51",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.4.7 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T20:00:37.510560Z",
     "start_time": "2025-05-09T20:00:34.671444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import neptune\n",
    "import neptune.integrations.optuna as optuna_utils\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=\"casvi/CodeMedic\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIzMTMzYjhhOC1jYzA1LTQ0YjAtOTJjNi1iY2EzM2VhMDY0OTcifQ==\"\n",
    ")\n"
   ],
   "id": "160f76e36b3713f2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[neptune] [warning] NeptuneWarning: By default, these monitoring options are disabled in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', 'capture_hardware_metrics'. You can set them to 'True' when initializing the run and the monitoring will continue until you call run.stop() or the kernel stops. NOTE: To track the source files, pass their paths to the 'source_code' argument. For help, see: https://docs-legacy.neptune.ai/logging/source_code/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/casvi/CodeMedic/e/COD-33\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T20:00:41.630250Z",
     "start_time": "2025-05-09T20:00:41.626244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load('rouge')\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "acc = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    if isinstance(logits, tuple):\n",
    "        # Depending on the model and config, logits may contain extra tensors,\n",
    "        # like past_key_values, but logits always come first\n",
    "        logits = logits[0]\n",
    "    # argmax to get the token ids\n",
    "    return logits.argmax(dim=-1)\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    # preds have the same shape as the labels,\n",
    "    # after the argmax(-1) has been calculated by preprocess_logits_for_metrics\n",
    "    # but we need to shift the labels\n",
    "    labels = labels[:, 1:]\n",
    "    preds = preds[:, :-1]\n",
    "\n",
    "    # -100 is a default value for ignore_index used by DataCollatorForCompletionOnlyLM\n",
    "    mask = labels == -100\n",
    "    # replace -100 with a value that the tokenizer can decode\n",
    "    labels[mask] = tokenizer.pad_token_id\n",
    "    preds[mask] = tokenizer.pad_token_id\n",
    "\n",
    "    # bleu takes in text, so we have to translate from token ids to text\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    bleu_score = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    # accuracy takes in lists of integers,\n",
    "    # and we want to evaluate only the parts that are not -100,\n",
    "    # hence the mask negation (~)\n",
    "    accuracy = acc.compute(predictions=preds[~mask], references=labels[~mask])\n",
    "\n",
    "    return {**bleu_score, **accuracy}"
   ],
   "id": "52ad9b6c952384ed",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T20:00:41.678608Z",
     "start_time": "2025-05-09T20:00:41.672644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "import time\n",
    "def objective(trial):\n",
    "    start=time.time()\n",
    "    # Suggest hyperparameters\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5,5e-4, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"per_device_train_batch_size\", [8,12,16])\n",
    "    gradient_accumulation_steps = trial.suggest_categorical(\"gradient_accumulation_steps\",[8,12,16])\n",
    "    num_epochs = trial.suggest_int(\"num_train_epochs\", 3, 10)\n",
    "\n",
    "    # SFT Config\n",
    "    config = SFTConfig(\n",
    "        dataset_num_proc = 1,\n",
    "        output_dir=\"./outputs\",\n",
    "        dataset_text_field=\"question\",#Depends on the colum of your data set\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        num_train_epochs=num_epochs,\n",
    "        report_to=\"none\",\n",
    "        logging_steps=100,\n",
    "        max_steps=1000,\n",
    "        eval_accumulation_steps=100\n",
    "    )\n",
    "\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,  # base or PEFT model\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        args=config,\n",
    "        warmup_steps = 5,\n",
    "        weight_decay = 0.01,\n",
    "        compute_metrics = compute_metrics,\n",
    "        preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "    )\n",
    "    metrics = trainer.evaluate()\n",
    "    trainer.train()\n",
    "    # Log trial info to Neptunef\n",
    "    run[f\"trial/{trial.number}/metrics\"] = metrics\n",
    "    run[f\"trial/{trial.number}/params\"] = {\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"num_epochs\": num_epochs,\n",
    "    }\n",
    "    print(\"Metrics:\",metrics)\n",
    "\n",
    "    end = time.time()\n",
    "    length = end - start\n",
    "\n",
    "    hours = int(length // 3600)\n",
    "    minutes = int((length % 3600) // 60)\n",
    "    seconds = int(length % 60)\n",
    "\n",
    "    print(f\"It took {hours} hours, {minutes} minutes, and {seconds} seconds to train the model!\")\n",
    "\n",
    "    return metrics[\"eval_loss\"]  # Or any other metric\n"
   ],
   "id": "919be25a4a8b1e6e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T20:04:17.831571Z",
     "start_time": "2025-05-09T20:00:41.723881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import optuna\n",
    "neptune_callback = optuna_utils.NeptuneCallback(run)\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10, callbacks=[neptune_callback], show_progress_bar=True)"
   ],
   "id": "7836cb53bd036bf1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 14:00:41,726] A new study created in memory with name: no-name-f9fe4e58-8a97-443d-b8e7-9e908c325658\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]Unsloth: Not an error, but Qwen3ForCausalLM does not accept `num_items_in_batch`.\n",
      "Using gradient accumulation will be very slightly less accurate.\n",
      "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1485' max='1485' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1485/1485 03:32]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [03:35<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-05-09 14:04:16,804] Trial 0 failed with parameters: {'learning_rate': 1.2745429344030691e-05, 'per_device_train_batch_size': 8, 'gradient_accumulation_steps': 16, 'num_train_epochs': 8} because of the following error: ValueError(\"invalid literal for int() with base 10: 'i'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\casvi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\casvi\\AppData\\Local\\Temp\\ipykernel_9668\\805129094.py\", line 37, in objective\n",
      "    metrics = trainer.evaluate()\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\casvi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\trainer.py\", line 4154, in evaluate\n",
      "    output = eval_loop(\n",
      "             ^^^^^^^^^^\n",
      "  File \"C:\\Users\\casvi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\trainer.py\", line 4443, in evaluation_loop\n",
      "    metrics = self.compute_metrics(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\casvi\\AppData\\Local\\Temp\\ipykernel_9668\\3035810745.py\", line 29, in compute_metrics\n",
      "    precision = precision_metric.compute(predictions=pred_str, references=label_str)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\casvi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\evaluate\\module.py\", line 455, in compute\n",
      "    self.add_batch(**inputs)\n",
      "  File \"C:\\Users\\casvi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\evaluate\\module.py\", line 520, in add_batch\n",
      "    batch = self.selected_feature_format.encode_batch(batch)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\casvi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\features\\features.py\", line 2083, in encode_batch\n",
      "    encoded_batch[key] = [encode_nested_example(self[key], obj, level=1) for obj in column]\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\casvi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\features\\features.py\", line 1362, in encode_nested_example\n",
      "    return schema.encode_example(obj) if obj is not None else None\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\casvi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\features\\features.py\", line 537, in encode_example\n",
      "    return int(value)\n",
      "           ^^^^^^^^^^\n",
      "ValueError: invalid literal for int() with base 10: 'i'\n",
      "[W 2025-05-09 14:04:16,824] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'i'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      2\u001B[39m neptune_callback = optuna_utils.NeptuneCallback(run)\n\u001B[32m      4\u001B[39m study = optuna.create_study(direction=\u001B[33m\"\u001B[39m\u001B[33mminimize\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m \u001B[43mstudy\u001B[49m\u001B[43m.\u001B[49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjective\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mneptune_callback\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\study.py:475\u001B[39m, in \u001B[36mStudy.optimize\u001B[39m\u001B[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[39m\n\u001B[32m    373\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34moptimize\u001B[39m(\n\u001B[32m    374\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    375\u001B[39m     func: ObjectiveFuncType,\n\u001B[32m   (...)\u001B[39m\u001B[32m    382\u001B[39m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    383\u001B[39m ) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    384\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[32m    385\u001B[39m \n\u001B[32m    386\u001B[39m \u001B[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    473\u001B[39m \u001B[33;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[32m    474\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m475\u001B[39m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    476\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    477\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    478\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    479\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    480\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    481\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    482\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    483\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    484\u001B[39m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    485\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001B[39m, in \u001B[36m_optimize\u001B[39m\u001B[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[39m\n\u001B[32m     61\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     62\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs == \u001B[32m1\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m63\u001B[39m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     64\u001B[39m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     65\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     66\u001B[39m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     67\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     68\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     69\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     70\u001B[39m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     71\u001B[39m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     72\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     73\u001B[39m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     74\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     75\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     76\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs == -\u001B[32m1\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001B[39m, in \u001B[36m_optimize_sequential\u001B[39m\u001B[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[39m\n\u001B[32m    157\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m    159\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m160\u001B[39m     frozen_trial = \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    161\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    162\u001B[39m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[32m    163\u001B[39m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[32m    164\u001B[39m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[32m    165\u001B[39m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[32m    166\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001B[39m, in \u001B[36m_run_trial\u001B[39m\u001B[34m(study, func, catch)\u001B[39m\n\u001B[32m    241\u001B[39m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mShould not reach.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    243\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    244\u001B[39m     frozen_trial.state == TrialState.FAIL\n\u001B[32m    245\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    246\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[32m    247\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m248\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[32m    249\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001B[39m, in \u001B[36m_run_trial\u001B[39m\u001B[34m(study, func, catch)\u001B[39m\n\u001B[32m    195\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001B[32m    196\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m197\u001B[39m         value_or_values = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    198\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions.TrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    199\u001B[39m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[32m    200\u001B[39m         state = TrialState.PRUNED\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 37\u001B[39m, in \u001B[36mobjective\u001B[39m\u001B[34m(trial)\u001B[39m\n\u001B[32m     12\u001B[39m config = SFTConfig(\n\u001B[32m     13\u001B[39m     dataset_num_proc = \u001B[32m1\u001B[39m,\n\u001B[32m     14\u001B[39m     output_dir=\u001B[33m\"\u001B[39m\u001B[33m./outputs\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     23\u001B[39m     eval_accumulation_steps=\u001B[32m100\u001B[39m\n\u001B[32m     24\u001B[39m )\n\u001B[32m     26\u001B[39m trainer = SFTTrainer(\n\u001B[32m     27\u001B[39m     model=model,  \u001B[38;5;66;03m# base or PEFT model\u001B[39;00m\n\u001B[32m     28\u001B[39m     tokenizer=tokenizer,\n\u001B[32m   (...)\u001B[39m\u001B[32m     35\u001B[39m     preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n\u001B[32m     36\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m37\u001B[39m metrics = \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     38\u001B[39m trainer.train()\n\u001B[32m     39\u001B[39m \u001B[38;5;66;03m# Log trial info to Neptunef\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\trainer.py:4154\u001B[39m, in \u001B[36mTrainer.evaluate\u001B[39m\u001B[34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001B[39m\n\u001B[32m   4151\u001B[39m start_time = time.time()\n\u001B[32m   4153\u001B[39m eval_loop = \u001B[38;5;28mself\u001B[39m.prediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.use_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.evaluation_loop\n\u001B[32m-> \u001B[39m\u001B[32m4154\u001B[39m output = \u001B[43meval_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4155\u001B[39m \u001B[43m    \u001B[49m\u001B[43meval_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4156\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mEvaluation\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   4157\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001B[39;49;00m\n\u001B[32m   4158\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# self.args.prediction_loss_only\u001B[39;49;00m\n\u001B[32m   4159\u001B[39m \u001B[43m    \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   4160\u001B[39m \u001B[43m    \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4161\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4162\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4164\u001B[39m total_batch_size = \u001B[38;5;28mself\u001B[39m.args.eval_batch_size * \u001B[38;5;28mself\u001B[39m.args.world_size\n\u001B[32m   4165\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_key_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_jit_compilation_time\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output.metrics:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\trainer.py:4443\u001B[39m, in \u001B[36mTrainer.evaluation_loop\u001B[39m\u001B[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[39m\n\u001B[32m   4441\u001B[39m     eval_set_kwargs[\u001B[33m\"\u001B[39m\u001B[33mlosses\u001B[39m\u001B[33m\"\u001B[39m] = all_losses \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mloss\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m args.include_for_metrics \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   4442\u001B[39m     eval_set_kwargs[\u001B[33m\"\u001B[39m\u001B[33minputs\u001B[39m\u001B[33m\"\u001B[39m] = all_inputs \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33minputs\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m args.include_for_metrics \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m4443\u001B[39m     metrics = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4444\u001B[39m \u001B[43m        \u001B[49m\u001B[43mEvalPrediction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mall_preds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mall_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43meval_set_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4445\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4446\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m metrics \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   4447\u001B[39m     metrics = {}\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 29\u001B[39m, in \u001B[36mcompute_metrics\u001B[39m\u001B[34m(eval_pred)\u001B[39m\n\u001B[32m     25\u001B[39m label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m     28\u001B[39m \u001B[38;5;66;03m#accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m29\u001B[39m precision = \u001B[43mprecision_metric\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcompute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpred_str\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreferences\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlabel_str\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     30\u001B[39m \u001B[38;5;66;03m#recall = recall_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\u001B[39;00m\n\u001B[32m     31\u001B[39m \u001B[38;5;66;03m#f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\u001B[39;00m\n\u001B[32m     33\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[32m     34\u001B[39m     \u001B[38;5;66;03m#\"accuracy\": accuracy[\"accuracy\"],\u001B[39;00m\n\u001B[32m     35\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mprecision\u001B[39m\u001B[33m\"\u001B[39m: precision[\u001B[33m\"\u001B[39m\u001B[33mprecision\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m     36\u001B[39m     \u001B[38;5;66;03m#\"recall\": recall[\"recall\"],\u001B[39;00m\n\u001B[32m     37\u001B[39m     \u001B[38;5;66;03m#\"f1\": f1[\"f1\"]\u001B[39;00m\n\u001B[32m     38\u001B[39m }\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\evaluate\\module.py:455\u001B[39m, in \u001B[36mEvaluationModule.compute\u001B[39m\u001B[34m(self, predictions, references, **kwargs)\u001B[39m\n\u001B[32m    452\u001B[39m compute_kwargs = {k: kwargs[k] \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m kwargs \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._feature_names()}\n\u001B[32m    454\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(v \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m inputs.values()):\n\u001B[32m--> \u001B[39m\u001B[32m455\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43madd_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    456\u001B[39m \u001B[38;5;28mself\u001B[39m._finalize()\n\u001B[32m    458\u001B[39m \u001B[38;5;28mself\u001B[39m.cache_file_name = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\evaluate\\module.py:520\u001B[39m, in \u001B[36mEvaluationModule.add_batch\u001B[39m\u001B[34m(self, predictions, references, **kwargs)\u001B[39m\n\u001B[32m    518\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(column) > \u001B[32m0\u001B[39m:\n\u001B[32m    519\u001B[39m             \u001B[38;5;28mself\u001B[39m._enforce_nested_string_type(\u001B[38;5;28mself\u001B[39m.selected_feature_format[key], column[\u001B[32m0\u001B[39m])\n\u001B[32m--> \u001B[39m\u001B[32m520\u001B[39m     batch = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mselected_feature_format\u001B[49m\u001B[43m.\u001B[49m\u001B[43mencode_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    521\u001B[39m     \u001B[38;5;28mself\u001B[39m.writer.write_batch(batch)\n\u001B[32m    522\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m (pa.ArrowInvalid, \u001B[38;5;167;01mTypeError\u001B[39;00m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\features\\features.py:2083\u001B[39m, in \u001B[36mFeatures.encode_batch\u001B[39m\u001B[34m(self, batch)\u001B[39m\n\u001B[32m   2081\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m key, column \u001B[38;5;129;01min\u001B[39;00m batch.items():\n\u001B[32m   2082\u001B[39m     column = cast_to_python_objects(column)\n\u001B[32m-> \u001B[39m\u001B[32m2083\u001B[39m     encoded_batch[key] = [\u001B[43mencode_nested_example\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m column]\n\u001B[32m   2084\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m encoded_batch\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\features\\features.py:1362\u001B[39m, in \u001B[36mencode_nested_example\u001B[39m\u001B[34m(schema, obj, level)\u001B[39m\n\u001B[32m   1359\u001B[39m \u001B[38;5;66;03m# Object with special encoding:\u001B[39;00m\n\u001B[32m   1360\u001B[39m \u001B[38;5;66;03m# ClassLabel will convert from string to int, TranslationVariableLanguages does some checks\u001B[39;00m\n\u001B[32m   1361\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(schema, \u001B[33m\"\u001B[39m\u001B[33mencode_example\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m-> \u001B[39m\u001B[32m1362\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mschema\u001B[49m\u001B[43m.\u001B[49m\u001B[43mencode_example\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1363\u001B[39m \u001B[38;5;66;03m# Other object should be directly convertible to a native Arrow type (like Translation and Translation)\u001B[39;00m\n\u001B[32m   1364\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m obj\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\features\\features.py:537\u001B[39m, in \u001B[36mValue.encode_example\u001B[39m\u001B[34m(self, value)\u001B[39m\n\u001B[32m    535\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mbool\u001B[39m(value)\n\u001B[32m    536\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m pa.types.is_integer(\u001B[38;5;28mself\u001B[39m.pa_type):\n\u001B[32m--> \u001B[39m\u001B[32m537\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    538\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m pa.types.is_floating(\u001B[38;5;28mself\u001B[39m.pa_type):\n\u001B[32m    539\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mfloat\u001B[39m(value)\n",
      "\u001B[31mValueError\u001B[39m: invalid literal for int() with base 10: 'i'"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T20:04:17.870088300Z",
     "start_time": "2025-05-09T01:48:37.875073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the best parameters\n",
    "best_trial = study.best_trial\n",
    "\n",
    "best_params = best_trial.params\n",
    "print(\"best_params: \",best_params)\n",
    "\n",
    "best_value = best_trial.value\n",
    "print(\"Eval loss:\", best_value)\n",
    "run.stop()"
   ],
   "id": "35c4630506ca94f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params:  {'learning_rate': 0.0001726174951678421, 'per_device_train_batch_size': 16, 'gradient_accumulation_steps': 16, 'num_train_epochs': 7}\n",
      "Eval loss: 3.690156936645508\n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 56 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 56 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/casvi/CodeMedic/e/COD-13/metadata\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T20:04:17.871123300Z",
     "start_time": "2025-05-09T01:48:44.626001Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "19606c381d8a011d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
