{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-07T06:47:34.085221Z",
     "start_time": "2025-05-07T06:47:31.185220Z"
    }
   },
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import os\n",
    "os.environ[\"WANDB_PROJECT\"] = \"qwen-coder-llm-fine-tuning\""
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\casvi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T06:47:38.263605Z",
     "start_time": "2025-05-07T06:47:34.362204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "wandb.login()"
   ],
   "id": "bc820cec7a97a11d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: casvi-sanchez (virtualtek) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T06:47:38.298988Z",
     "start_time": "2025-05-07T06:47:38.292986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "wandb.login()"
   ],
   "id": "6f2e3c44e2192693",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T06:47:47.702066Z",
     "start_time": "2025-05-07T06:47:38.356661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_name = \"squad_v2\"\n",
    "dataset = load_dataset(dataset_name, split=\"train\")\n",
    "eval_dataset = load_dataset(dataset_name, split=\"validation\")\n",
    "print(\"dataset: \",dataset)\n",
    "print(\"eval_dataset: \",eval_dataset)\n"
   ],
   "id": "500b473b559b567d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 130319\n",
      "})\n",
      "eval_dataset:  Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "    num_rows: 11873\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T06:47:53.305898Z",
     "start_time": "2025-05-07T06:47:47.732552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "if cuda_available:\n",
    "    device_id = 0  # You can change to 1,2,3 if you want other GPUs\n",
    "    torch.cuda.set_device(device_id)\n",
    "    # device = torch.device(f\"cuda:{device_id}\")\n",
    "    device = torch.device(f\"cuda:{device_id}\")\n",
    "    print(f\"🖥️ Using GPU {device_id}: {torch.cuda.get_device_name(device_id)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"⚙️ No GPU available, using CPU.\")\n",
    "\n",
    "print(f\"Device selected: {device}\")"
   ],
   "id": "1febccd54d7494b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🖥️ Using GPU 0: NVIDIA GeForce RTX 4070 SUPER\n",
      "Device selected: cuda:0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T06:48:27.547347Z",
     "start_time": "2025-05-07T06:47:53.320930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from unsloth import FastLanguageModel\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen3-1.7B-unsloth-bnb-4bit\",\n",
    "    max_seq_length = 2048,   # Context length - can be longer, but uses more memory\n",
    "    load_in_4bit = True,     # 4bit uses much less memory\n",
    "    load_in_8bit = False,    # A bit more accurate, uses 2x memory\n",
    "    full_finetuning = False, # We have full finetuning now!\n",
    "    # token = \"hf_...\",      # use one if using gated models\n",
    "\n",
    ")"
   ],
   "id": "46eb93bfa905de57",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.4.7: Fast Qwen3 patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4070 SUPER. Num GPUs = 2. Max memory: 11.994 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T06:48:32.870856Z",
     "start_time": "2025-05-07T06:48:28.572780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 32,           # Choose any number > 0! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 32,  # Best to choose alpha = rank or rank*2\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,   # We support rank stabilized LoRA\n",
    "    loftq_config = None,  # And LoftQ\n",
    ")"
   ],
   "id": "27782ee8b927aa51",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.4.7 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T07:02:49.951789Z",
     "start_time": "2025-05-07T07:02:49.225917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import neptune\n",
    "import neptune.integrations.optuna as optuna_utils\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=\"casvi/CodeMedic\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIzMTMzYjhhOC1jYzA1LTQ0YjAtOTJjNi1iY2EzM2VhMDY0OTcifQ==\"\n",
    ")\n"
   ],
   "id": "160f76e36b3713f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/casvi/CodeMedic/e/COD-5\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T07:02:50.018891Z",
     "start_time": "2025-05-07T07:02:50.012665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "import time\n",
    "def objective(trial):\n",
    "    start=time.time()\n",
    "    # Suggest hyperparameters\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-4, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"per_device_train_batch_size\", [2, 4, 8])\n",
    "    num_epochs = trial.suggest_int(\"num_train_epochs\", 1, 3)\n",
    "\n",
    "    # SFT Config\n",
    "    config = SFTConfig(\n",
    "        dataset_num_proc = 1,\n",
    "        output_dir=\"./outputs\",\n",
    "        dataset_text_field=\"question\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        num_train_epochs=num_epochs,\n",
    "        report_to=\"none\",  # We log to Neptune manually\n",
    "        logging_steps=10,\n",
    "        max_steps=100,\n",
    "    )\n",
    "\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,  # base or PEFT model\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        args=config,\n",
    "        prediction_loss_only=False,\n",
    "        eval_accumulation_steps=10,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    # Log trial info to Neptune\n",
    "    run[f\"trial/{trial.number}/metrics\"] = metrics\n",
    "    run[f\"trial/{trial.number}/params\"] = {\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"num_epochs\": num_epochs,\n",
    "    }\n",
    "\n",
    "    end = time.time()\n",
    "    length = end - start\n",
    "\n",
    "    hours = int(length // 3600)\n",
    "    minutes = int((length % 3600) // 60)\n",
    "    seconds = int(length % 60)\n",
    "\n",
    "    print(f\"It took {hours} hours, {minutes} minutes, and {seconds} seconds to train the model!\")\n",
    "\n",
    "    return metrics[\"eval_loss\"]  # Or any other metric\n"
   ],
   "id": "919be25a4a8b1e6e",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T07:11:08.164001Z",
     "start_time": "2025-05-07T07:02:53.683748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import optuna\n",
    "neptune_callback = optuna_utils.NeptuneCallback(run)\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=2, callbacks=[neptune_callback], show_progress_bar=True)"
   ],
   "id": "7836cb53bd036bf1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 01:02:53,685] A new study created in memory with name: no-name-a4c602cf-57e0-49ff-9542-5cbd35a2bcba\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 130,319 | Num Epochs = 1 | Total steps = 100\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 2 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 34,865,152/7,000,000,000 (0.50% trained)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 01:22, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.065300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.829200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.692300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.872500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.920600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.886900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.908400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.674100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.753100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.757100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1485' max='1485' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1485/1485 02:44]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  TrainOutput(global_step=100, training_loss=3.8359455108642577, metrics={'train_runtime': 83.9233, 'train_samples_per_second': 9.533, 'train_steps_per_second': 1.192, 'total_flos': 116397026918400.0, 'train_loss': 3.8359455108642577})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 01:07:03,327] Trial 0 finished with value: 3.820232629776001 and parameters: {'learning_rate': 0.00016478552271182332, 'per_device_train_batch_size': 2, 'num_train_epochs': 1}. Best is trial 0 with value: 3.820232629776001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-05-07 01:07:03,337] Param num_train_epochs unique value length is less than 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-05-07 01:07:03,342] Param per_device_train_batch_size unique value length is less than 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-05-07 01:07:03,346] Param learning_rate unique value length is less than 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-05-07 01:07:03,351] Param per_device_train_batch_size unique value length is less than 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-05-07 01:07:03,354] Param learning_rate unique value length is less than 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-05-07 01:07:03,358] Param num_train_epochs unique value length is less than 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 3.82023:  50%|█████     | 1/2 [04:09<04:09, 249.93s/it]==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 130,319 | Num Epochs = 1 | Total steps = 100\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 2 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 34,865,152/7,000,000,000 (0.50% trained)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 01:21, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.105700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.236000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.536500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.655500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.780400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.858000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.855600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.678600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.708200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.704000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1485' max='1485' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1485/1485 02:39]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  TrainOutput(global_step=100, training_loss=3.611842384338379, metrics={'train_runtime': 82.7215, 'train_samples_per_second': 19.342, 'train_steps_per_second': 1.209, 'total_flos': 266347455283200.0, 'train_loss': 3.611842384338379})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 01:11:07,781] Trial 1 finished with value: 3.8060173988342285 and parameters: {'learning_rate': 0.0004614775923983271, 'per_device_train_batch_size': 4, 'num_train_epochs': 2}. Best is trial 1 with value: 3.8060173988342285.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 3.80602: 100%|██████████| 2/2 [08:14<00:00, 247.24s/it]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T07:24:13.638598Z",
     "start_time": "2025-05-07T07:24:13.630464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the best parameters\n",
    "best_trial = study.best_trial\n",
    "\n",
    "best_params = best_trial.params\n",
    "print(\"best_params: \",best_params)\n",
    "\n",
    "best_value = best_trial.value\n",
    "print(\"Eval loss:\", best_value)\n",
    "run.stop()"
   ],
   "id": "35c4630506ca94f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params:  {'learning_rate': 0.0004614775923983271, 'per_device_train_batch_size': 4, 'num_train_epochs': 2}\n",
      "Eval loss: 3.8060173988342285\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "19606c381d8a011d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
